# Real Call Chain - What Actually Exists vs What Needs to Happen

## ğŸ” Current State (What EXISTS Now)

### **Backend (mindmate-backend)**

**Existing Endpoints:**
```python
GET  /health                                    âœ… Working
GET  /patients                                  âœ… Working - returns list from Supabase
POST /patients                                  âœ… Working - creates in Supabase
GET  /sessions                                  âœ… Working - returns list from Supabase
POST /sessions                                  âœ… Working - creates in Supabase
POST /sessions/analyze/{session_id}             âš ï¸  STUB - just returns mock response
GET  /memories                                  âœ… Working - returns list from Supabase
POST /memories                                  âœ… Working - creates in Supabase
GET  /doctors                                   âœ… Working
POST /doctors                                   âœ… Working
GET  /doctor-records/{patient_id}               âœ… Working
POST /doctor-records                            âœ… Working
GET  /patients/{patient_id}/analytics           âš ï¸  HARDCODED - returns fake brain regions
```

**What's Hardcoded in `/patients/{patient_id}/analytics`:**
```python
# routes/sessions.py line 261-268
brain_regions = BrainRegionScores(
    hippocampus=82.5,          # âŒ FAKE
    prefrontalCortex=77.3,     # âŒ FAKE
    temporalLobe=85.2,         # âŒ FAKE
    parietalLobe=79.0,         # âŒ FAKE
    amygdala=88.4,             # âŒ FAKE
    cerebellum=83.0            # âŒ FAKE
)

memory_metrics = MemoryMetrics(
    shortTermRecall=[...],     # âœ… Uses session data
    longTermRecall=[],         # âŒ EMPTY
    semanticMemory=[],         # âŒ EMPTY
    episodicMemory=[],         # âŒ EMPTY
    workingMemory=[]           # âŒ EMPTY
)
```

### **Frontend (doctor-frontend)**

**API Calls Frontend Makes:**
```typescript
// lib/api/client.ts

api.health()                               âœ… Calls: GET /health
api.patients.list()                        âœ… Calls: GET /patients
api.patients.get(id)                       âœ… Calls: GET /patients/{id}
api.patients.create(data)                  âœ… Calls: POST /patients
api.patients.getCognitiveData(id)          âŒ Calls: GET /patients/{id}/cognitive-data (DOESN'T EXIST!)
api.sessions.list()                        âœ… Calls: GET /sessions
api.sessions.create(data)                  âœ… Calls: POST /sessions
api.memories.list()                        âœ… Calls: GET /memories
api.memories.create(data)                  âœ… Calls: POST /memories
```

**PROBLEM:** Frontend calls `/patients/{id}/cognitive-data` but backend has `/patients/{id}/analytics`!

---

## ğŸ¯ Real Data Flow (Current Implementation)

### **1. Doctor Opens Dashboard**

```
Doctor opens doctor-frontend
  â†“
Frontend calls: api.patients.getCognitiveData(patient_id)
  â†“
GET /patients/{patient_id}/cognitive-data
  â†“
âŒ 404 NOT FOUND - This endpoint doesn't exist!
  â†“
Frontend shows error or uses mock data
```

**Alternative (if they fix the endpoint name):**
```
Frontend calls: GET /patients/{patient_id}/analytics
  â†“
Backend (routes/sessions.py:252)
  â†“
Fetches from Supabase:
  - patient data
  - sessions data
  â†“
Returns HARDCODED brain regions + basic session scores
  â†“
Frontend displays fake brain region data
```

### **2. Patient Has Video Call** (stellar-mind-companion)

```
User opens stellar-mind-companion
  â†“
LiveKit video call
  â†“
Transcript generated
  â†“
Frontend calls: POST /sessions
  {
    patient_id: "uuid",
    transcript: "conversation text...",
    exercise_type: "memory_recall"
  }
  â†“
Backend stores in Supabase
  â†“
Returns session_id
```

**Then (if analysis is triggered):**
```
Frontend (or timer) calls: POST /sessions/analyze/{session_id}
  â†“
Backend (routes/sessions.py:89)
  â†“
Just returns: {"status": "Analysis started in background.", "session_id": "..."}
  â†“
âŒ NO ACTUAL ANALYSIS HAPPENS - It's a stub!
```

---

## ğŸš€ What SHOULD Happen (After Integration)

### **Complete Integration Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. VIDEO CALL ENDS                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
stellar-mind-companion â†’ POST /sessions
                         â”‚ {patient_id, transcript}
                         â†“
                    Supabase stores
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TRIGGER ANALYSIS (automatic or manual)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
Frontend/Cron â†’ POST /sessions/analyze/{session_id}
                         â†“
Backend (UPDATED routes/sessions.py)
                         â”‚
                         â”œâ”€ Fetch session from Supabase
                         â”œâ”€ Fetch patient from Supabase
                         â”œâ”€ Fetch previous sessions
                         â”‚
                         â†“
                    CALL COGNITIVE API
                         â”‚
    POST https://mindmate-cognitive-api.onrender.com/analyze/session
    {
      session_id: "...",
      patient_id: "...",
      transcript: "...",
      patient_profile: {...},
      previous_sessions: [...]
    }
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COGNITIVE API PROCESSING                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
    services/session_analyzer.py
                         â”‚
      â”œâ”€ Dedalus AI: Extract memories
      â”‚  â””â”€ Returns: [{title, description, emotional_tone}, ...]
      â”‚
      â”œâ”€ tools/cognitive_assessment.py
      â”‚  â””â”€ Returns: {temporal: 0.7, recall: 0.6, speech: 0.75}
      â”‚
      â””â”€ tools/memory_metrics_engine.py
         â””â”€ Returns: {
              shortTermRecall: 0.65,
              longTermRecall: 0.58,
              semanticMemory: 0.72,
              episodicMemory: 0.55,
              workingMemory: 0.68
            }
                         â”‚
                         â†“
        Returns to Backend:
        {
          "overall_score": 0.65,
          "memories": [...],
          "cognitive_test_scores": [...],
          "memory_metrics": {...},
          "doctor_alerts": [...]
        }
                         â”‚
                         â†“
Backend stores in Supabase:
  - ai_extracted_data
  - cognitive_test_scores
  - memory_metrics
  - overall_score
                         â”‚
Backend stores memories in ChromaDB
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. DOCTOR VIEWS DASHBOARD                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
Doctor opens dashboard â†’ GET /patients/{id}/analytics
                         â†“
Backend (UPDATED routes/sessions.py)
                         â”‚
                         â”œâ”€ Fetch patient from Supabase
                         â”œâ”€ Fetch all sessions from Supabase
                         â”‚
                         â†“
                    CALL COGNITIVE API
                         â”‚
POST https://mindmate-cognitive-api.onrender.com/patient/dashboard
{
  patient_id: "...",
  patient_name: "...",
  sessions: [...30 sessions with ai_extracted_data...],
  mri_csv_path: "data/mri/patient_001.csv"
}
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COGNITIVE API DASHBOARD GENERATION                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
      Check cache (24hr TTL)
                         â”‚
                         â”œâ”€ Cache hit? Return cached
                         â”‚
                         â””â”€ Cache miss:
                              â”‚
        tools/brain_region_mapper.py
          â”œâ”€ Read MRI CSV
          â””â”€ Returns: {
                hippocampus: 0.75 (REAL from CSV),
                prefrontalCortex: 0.80 (REAL calculated),
                ...
              }
                              â”‚
        tools/memory_metrics_engine.py
          â”œâ”€ Process 30 sessions with ai_extracted_data
          â””â”€ Returns time series for all 5 metrics:
              {
                shortTermRecall: [{timestamp, score}, ...],
                longTermRecall: [{timestamp, score}, ...],
                semanticMemory: [{timestamp, score}, ...],
                episodicMemory: [{timestamp, score}, ...],
                workingMemory: [{timestamp, score}, ...]
              }
                              â”‚
        Combine into PatientData format
                         â”‚
                         â†“
        Returns to Backend:
        {
          patientId: "...",
          patientName: "...",
          brainRegions: {...REAL DATA...},
          memoryMetrics: {...REAL TIME SERIES...},
          recentSessions: [...],
          overallCognitiveScore: 0.68,
          memoryRetentionRate: 0.65
        }
                         â”‚
                         â†“
Backend returns to Frontend
                         â”‚
                         â†“
Frontend displays REAL charts with REAL data
```

---

## ğŸ“Š Summary: Fake vs Real

### **Currently FAKE:**

âŒ Brain region scores (hardcoded to 82.5, 77.3, etc.)
âŒ Memory metrics (longTerm, semantic, episodic, working all empty)
âŒ Session analysis (stub that does nothing)
âŒ Memory extraction (not happening)
âŒ Risk alerts (not generated)

### **Currently REAL:**

âœ… Supabase database connection
âœ… Patient CRUD operations
âœ… Session CRUD operations
âœ… Memory CRUD operations
âœ… Doctor records
âœ… Basic session storage

### **After Integration - Will Be REAL:**

âœ… Brain regions from actual MRI CSV files
âœ… All 5 memory metrics with time series data
âœ… Dedalus AI memory extraction
âœ… Cognitive test scoring
âœ… Doctor risk alerts
âœ… Complete analytics pipeline

---

## ğŸ”§ What Needs to Change

### **1. Fix Frontend Endpoint Mismatch**

Either:
- Change frontend to call `/patients/{id}/analytics` instead of `/cognitive-data`
- OR add alias in backend: `/patients/{id}/cognitive-data` â†’ `/analytics`

### **2. Deploy Cognitive API**

- Deploy models repo to Render
- Get URL: `https://mindmate-cognitive-api.onrender.com`

### **3. Update Backend**

Add to backend repo:
- `services/cognitive_api_client.py` - Client to call Cognitive API
- Update `routes/sessions.py`:
  - `POST /sessions/analyze/{id}` - Call Cognitive API instead of stub
  - `GET /patients/{id}/analytics` - Call Cognitive API for dashboard

### **4. Update Frontend**

- Fix endpoint name mismatch
- Add loading states for analysis (60-120 seconds)
- Handle real-time data instead of mock data

---

## ğŸ¯ Priority Order

1. **Deploy Cognitive API** (5 min) - Makes it available
2. **Fix endpoint mismatch** (2 min) - Frontend can call backend
3. **Update backend with integration** (15 min) - Connects everything
4. **Test with real data** (10 min) - Verify it works
5. **Deploy updated backend** (5 min) - Make it live

**Total: ~40 minutes to go from fake data to real AI-powered analysis**
